{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook data ðŸ“ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to fix encoding of message.json file. To do this, we will encode message to **latin-1** and decode to **utf8**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "from PyQt6 import QtWidgets\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "def open_files():\n",
    "    app = QtWidgets.QApplication([dir])\n",
    "    fnames = QtWidgets.QFileDialog.getOpenFileNames(None, \"Select a file...\", '.', filter=\"All files (*)\")\n",
    "    return sorted(fnames[0], key=lambda name : int(name.split(\".\")[0].split(\"_\")[-1]) )\n",
    "\n",
    "\n",
    "file_names = open_files()\n",
    "result_name = '{}_merged.json'.format(os.path.splitext(file_names[0])[0])\n",
    "\n",
    "print('Working ...')\n",
    "\n",
    "result_json = None\n",
    "\n",
    "def processValue(value):\n",
    "    if type(value) is dict:\n",
    "        processDict(value)\n",
    "    elif type(value) is list:\n",
    "        for index, item in enumerate(value): \n",
    "            value[index] = processValue(item)\n",
    "    elif type(value) is str:\n",
    "        return value.encode('latin-1').decode('utf8')\n",
    "\n",
    "    return value\n",
    "\n",
    "def processDict(dictionary):\n",
    "    for key, val in dictionary.items():\n",
    "        dictionary[key] = processValue(val)\n",
    "    \n",
    "datas = None\n",
    "for file_name in file_names:\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        data_dict = json.load(file)\n",
    "\n",
    "        processDict(data_dict)\n",
    "\n",
    "        if not datas:\n",
    "            datas = data_dict\n",
    "        else:\n",
    "            for key, val in data_dict.items():\n",
    "                if key == \"messages\":\n",
    "                    continue\n",
    "                if datas[key] != val:\n",
    "                    raise Exception(\"Message files contain different metadata\")\n",
    "                \n",
    "            datas[\"messages\"].extend(data_dict[\"messages\"])\n",
    "\n",
    "with open(result_name, 'w', encoding='utf8') as fout:\n",
    "    json.dump(datas, fout, indent=2, ensure_ascii=False)\n",
    "\n",
    "print('File created at {}'.format(result_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SQLITE database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start making some cool stats ðŸ’» top **n messages** from conversation ðŸ“–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_split_pattern = r'[ ,.?!\\n]'\n",
    "\n",
    "def splitMessageToWords(msg):\n",
    "    parts = re.split(word_split_pattern, msg)\n",
    "\n",
    "    return list(filter(None, parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import islice\n",
    "\n",
    "file = open(result_name, 'r', encoding='utf8')\n",
    "\n",
    "msg_json = json.load(file)\n",
    "\n",
    "# Count every word\n",
    "\n",
    "messagesAll = {}\n",
    "photos = []\n",
    "videos = []\n",
    "\n",
    "for msg in msg_json['messages']:\n",
    "    if \"content\" in msg:\n",
    "        tmp = []\n",
    "       # tmp = re.findall(r\"[\\w']+\", i['content']) not sure which is better ðŸ˜¶\n",
    "        tmp = splitMessageToWords(msg['content'].lower())\n",
    "        \n",
    "        for word in tmp:\n",
    "            if word in messagesAll:\n",
    "                messagesAll[word] += 1\n",
    "            else:\n",
    "                messagesAll[word] = 1\n",
    "    elif \"photos\" in msg:\n",
    "        photos.append(msg)\n",
    "    elif \"videos\" in msg:\n",
    "        videos.append(msg)\n",
    "\n",
    "sortedAll = sorted(messagesAll.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "def first_n_from_iterable(n, iterable):\n",
    "    \"\"\"Return first n items of the iterable as a list\"\"\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "def get_top_messages(dict_msgs, n=10):\n",
    "    \"\"\"Return first n messages of dict\"\"\"\n",
    "\n",
    "    print('\\nTop {} :\\n'.format(n))\n",
    "    for key in first_n_from_iterable(n, dict_msgs):\n",
    "        print(key)\n",
    "        \n",
    "get_top_messages(sortedAll, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO Top messages per month / year ðŸ“† and create dictionary with month and total messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "messages_per_month_dict = {}\n",
    "user_messages_per_month = {}\n",
    "\n",
    "def get_messages_per_month():\n",
    "    for i in msg_json['messages']:\n",
    "        date = str(datetime.datetime.fromtimestamp(float(i['timestamp_ms'])/ 1000.0).strftime('%Y-%B'))\n",
    "        sender = i['sender_name']\n",
    "        \n",
    "        if date in messages_per_month_dict:\n",
    "            messages_per_month_dict[date] += 1\n",
    "        else:\n",
    "            messages_per_month_dict[date] = 1\n",
    "        \n",
    "        if sender in user_messages_per_month:\n",
    "            if date in user_messages_per_month[sender]:\n",
    "                user_messages_per_month[sender][date] += 1\n",
    "            else:\n",
    "                user_messages_per_month[sender][date] = 1\n",
    "        else:\n",
    "            user_messages_per_month[sender] = {}\n",
    "            user_messages_per_month[sender][date] = 1\n",
    "        \n",
    "        \n",
    "get_messages_per_month()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 per sender #TODO group chat ðŸ’¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_word_counts = {}\n",
    "sorted_user_word_counts = {}\n",
    "\n",
    "for msg in msg_json['messages']:\n",
    "    try:\n",
    "        tmp = []\n",
    "       # tmp = re.findall(r\"[\\w']+\", i['content']) # dont know which is better\n",
    "        tmp = splitMessageToWords(msg['content'].lower())\n",
    "        date = msg['sender_name']\n",
    "        \n",
    "        if date not in user_word_counts:\n",
    "            user_word_counts[date] = {}\n",
    "        \n",
    "        for word in tmp:\n",
    "            if word in user_word_counts[date]:\n",
    "                user_word_counts[date][word] += 1\n",
    "            else:\n",
    "                user_word_counts[date][word] = 1\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "for user in user_word_counts.keys():\n",
    "    sorted_user_word_counts[user] = sorted(user_word_counts[user].items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "def get_top_messages_per_sender(dicts, n=10):\n",
    "    \"\"\"Return first n messages per sender\"\"\"\n",
    "    \n",
    "    for sender in dicts.keys():\n",
    "        print('\\nTop {} from : {}'.format(n, sender))\n",
    "        for key in first_n_from_iterable(n, dicts[sender]):\n",
    "            print(key)\n",
    "\n",
    "get_top_messages_per_sender(sorted_user_word_counts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your conversation contains some youtube videos (of cource does ðŸ˜‰) you can search for them and their titles! â–¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from lxml import etree\n",
    "\n",
    "def get_youtube_titles_from_conversation():\n",
    " # delete to run this, otherwise its slow af\n",
    "    videoCount = 0\n",
    "    for i in msg_json['messages']:\n",
    "        try:\n",
    "            tmp = []\n",
    "            tmp = i['content'].split()\n",
    "            for word in tmp:\n",
    "                if 'youtube.com/watch' in word:\n",
    "                    try:\n",
    "                        youtube = etree.HTML(urlopen(word).read())\n",
    "                        video_title = youtube.xpath(\n",
    "                            \"//span[@id='eow-title']/@title\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        video_title = 'Error'\n",
    "\n",
    "                    print('{} -> {}'.format(word, video_title))\n",
    "                    videoCount += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "#get_youtube_titles_from_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make some graphs(finally)! ðŸŽ‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def key_fnc(elem):\n",
    "    return datetime.datetime.strptime(elem, '%Y-%B')\n",
    "\n",
    "x_axe = list(messages_per_month_dict.keys())\n",
    "x_axe_sorted = sorted(x_axe, key=key_fnc)\n",
    "\n",
    "y_axe = []\n",
    "for key in x_axe_sorted:\n",
    "    y_axe.append(messages_per_month_dict[key])\n",
    "\n",
    "\n",
    "plotly.offline.plot({\n",
    "    \"data\": [go.Scatter(x=x_axe_sorted, y=y_axe)],\n",
    "    \"layout\": go.Layout(title=\"Month graph ðŸŽ‰\")\n",
    "}, auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per sender message graph ðŸŽˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "def key_fnc(elem):\n",
    "    return datetime.datetime.strptime(elem, '%Y-%B')\n",
    "\n",
    "x_axe = list(messages_per_month_dict.keys())\n",
    "x_axe_sorted = sorted(x_axe, key=key_fnc)\n",
    "\n",
    "data = []\n",
    "\n",
    "for date in user_messages_per_month.keys():\n",
    "    y_sender = []\n",
    "    for emojo in x_axe_sorted:\n",
    "        if(emojo not in user_messages_per_month[date]):\n",
    "            y_sender.append(0)\n",
    "        else:\n",
    "            y_sender.append(user_messages_per_month[date][emojo])\n",
    "\n",
    "    r = lambda: random.randint(0,255)\n",
    "    graph_color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "    \n",
    "    sender_msg = go.Scatter(\n",
    "                x=x_axe_sorted,\n",
    "                y=y_sender,\n",
    "                name = date,\n",
    "                line = dict(color = graph_color),\n",
    "                opacity = 0.8)\n",
    "    data.append(sender_msg)\n",
    "\n",
    "plotly.offline.plot({\n",
    "    \"data\": data,\n",
    "    \"layout\": go.Layout(title=\"Month graph ðŸŽ‰\")\n",
    "}, auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordPatternCount(pattern):\n",
    "    count = 0\n",
    "    variants = []\n",
    "\n",
    "    for word in messagesAll:\n",
    "        if re.match(pattern, word):\n",
    "            count += messagesAll[word]\n",
    "            variants.append(word)\n",
    "\n",
    "    return count, variants\n",
    "\n",
    "be_pattern = r\"\\b(be)+$\"\n",
    "wordPatternCount(be_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuj_pattern = r\"\\b(fu+j)+\\b\"\n",
    "count, variants = wordPatternCount(fuj_pattern)\n",
    "\n",
    "print(count, len(variants))\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fej_pattern = r\"\\b(fe+j)+\\b\"\n",
    "count, variants = wordPatternCount(fej_pattern)\n",
    "\n",
    "print(count, len(variants))\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otrasz_pattern = r\"\\b(otra(s|z))\\b\"\n",
    "count, variants = wordPatternCount(otrasz_pattern)\n",
    "\n",
    "print(count, len(variants))\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "emoji_pattern = re.compile(r\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002600-\\U000026FF\\U00002700-\\U000027BF\\U00002300-\\U000023FF\\U00002B50]\")\n",
    "\n",
    "emojis = defaultdict(int)\n",
    "\n",
    "for msg in msg_json[\"messages\"]:\n",
    "    if \"content\" in msg:\n",
    "        matches = re.findall(emoji_pattern, msg['content'])\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                emojis[match] += 1\n",
    "\n",
    "print(sorted(emojis.items(), key=lambda kv : kv[1], reverse=True))\n",
    "\n",
    "print(emojis.keys())\n",
    "print(sum(emojis.values()))\n",
    "print(len(emojis.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronological_messages = sorted(msg_json[\"messages\"], key= lambda x : x[\"timestamp_ms\"])\n",
    "\n",
    "start_date = datetime.fromtimestamp(float(chronological_messages[0][\"timestamp_ms\"])/ 1000.0)\n",
    "end_date = datetime.fromtimestamp(float(chronological_messages[-1][\"timestamp_ms\"])/ 1000.0)\n",
    "\n",
    "month = start_date.month\n",
    "num_months = (12 - month) + (end_date.year - start_date.year - 1) * 12 + end_date.month\n",
    "\n",
    "emojis_per_month_dict = {}\n",
    "\n",
    "for m in range(month - 1, month + num_months + 1):\n",
    "    mnth = m % 12 + 1\n",
    "    yr =  start_date.year + m // 12\n",
    "\n",
    "    emojis_per_month_dict[datetime(yr, mnth, 1, 0, 0, 0, 0).strftime('%Y-%B')] = defaultdict(defaultdict)\n",
    "\n",
    "\n",
    "def get_emojis_per_month():\n",
    "    for msg in chronological_messages:\n",
    "        date = str(datetime.fromtimestamp(float(msg['timestamp_ms'])/ 1000.0).strftime('%Y-%B'))\n",
    "        emoji_dict = emojis_per_month_dict[date]\n",
    "\n",
    "        if \"content\" in msg:\n",
    "            matches = re.findall(emoji_pattern, msg['content'])\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    if not match in emoji_dict:\n",
    "                        emoji_dict[match] = 0\n",
    "\n",
    "                    emoji_dict[match] += 1\n",
    "\n",
    "        \n",
    "get_emojis_per_month()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_per_month_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_fnc(elem):\n",
    "    return datetime.strptime(elem, '%Y-%B')\n",
    "\n",
    "x_axe = list(emojis_per_month_dict.keys())\n",
    "x_axe_sorted = sorted(x_axe, key=key_fnc)\n",
    "\n",
    "data = []\n",
    "\n",
    "for emojo in emojis.keys():\n",
    "    y_emojo = []\n",
    "    for date in emojis_per_month_dict:\n",
    "        if(emojo not in emojis_per_month_dict[date]):\n",
    "            y_emojo.append(0)\n",
    "        else:\n",
    "            y_emojo.append(emojis_per_month_dict[date][emojo])\n",
    "\n",
    "    r = lambda: random.randint(0,255)\n",
    "    graph_color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "    \n",
    "    sender_msg = go.Scatter(\n",
    "                x=x_axe_sorted,\n",
    "                y=y_emojo,\n",
    "                name = emojo,\n",
    "                line = dict(color = graph_color),\n",
    "                opacity = 0.8)\n",
    "    data.append(sender_msg)\n",
    "\n",
    "plotly.offline.plot({\n",
    "    \"data\": data,\n",
    "    \"layout\": go.Layout(title=\"EMOJOOOO graph ðŸŽ‰\")\n",
    "}, auto_open=True)\n",
    "\n",
    "# \"layout\": go.Layout(title=\"EMOJOOOO graph ðŸŽ‰\",yaxis=dict(\n",
    "#         title=\"Emoji\",\n",
    "#         type=\"log\",\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.strptime(\"2020-November\",'%Y-%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_by_sender = defaultdict(int)\n",
    "\n",
    "for photo_msg in photos:\n",
    "    photos_by_sender[photo_msg[\"sender_name\"]] += len(photo_msg[\"photos\"])\n",
    "\n",
    "photos_by_sender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_by_sender = defaultdict(int)\n",
    "\n",
    "for video_msg in videos:\n",
    "    videos_by_sender[video_msg[\"sender_name\"]] += len(video_msg[\"videos\"])\n",
    "\n",
    "videos_by_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in msg_json[\"messages\"]:\n",
    "    print(message[\"timestamp_ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronological_messages = sorted(msg_json[\"messages\"], key= lambda x : x[\"timestamp_ms\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = []\n",
    "\n",
    "#8h             s    m    h    \n",
    "treshold_ms = float(1000 * 60 * 60 * 8)\n",
    "\n",
    "last_message_timestamp = float(chronological_messages[0]['timestamp_ms'])\n",
    "convo = {\"first_message\" : chronological_messages[0], \"start_index\" : 0}\n",
    "for index, message in enumerate(chronological_messages):\n",
    "    timestamp = float(message['timestamp_ms'])\n",
    "\n",
    "    if (timestamp - last_message_timestamp) >= treshold_ms:\n",
    "        convo[\"last_message\"] = chronological_messages[index - 1]\n",
    "        convo[\"end_index\"] = index - 1\n",
    "        convo[\"timespan_ms\"] = float(convo[\"last_message\"]['timestamp_ms']) - float(convo[\"first_message\"]['timestamp_ms'])\n",
    "        convo[\"num_messages\"] = convo['end_index'] - convo['start_index'] + 1\n",
    "        convos.append(convo)\n",
    "        convo = {\"first_message\" : message, \"start_index\" : index}\n",
    "\n",
    "    last_message_timestamp = timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(convos))\n",
    "longest_convo = max(convos, key=lambda cnv : cnv['timespan_ms'])\n",
    "longest_convo[\"timespan_ms\"] / (1000.0 * 60 * 60)\n",
    "start = longest_convo[\"start_index\"]\n",
    "end = longest_convo[\"end_index\"]\n",
    "\n",
    "for i in range(start, end + 1):\n",
    "    print(chronological_messages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import csv\n",
    "\n",
    "ordered_photos = sorted(photos, key= lambda photo : photo['timestamp_ms'])\n",
    "\n",
    "photos_per_month_dict = defaultdict(list)\n",
    "\n",
    "for photo in ordered_photos:\n",
    "    date = str(datetime.fromtimestamp(float(photo['timestamp_ms'])/ 1000.0).strftime('%Y-%B'))\n",
    "    \n",
    "    photos_per_month_dict[date].append(photo)\n",
    "\n",
    "conversation_dir = os.path.split(result_name)[0]\n",
    "\n",
    "for month, messages in photos_per_month_dict.items():\n",
    "    month_directory = os.path.join(conversation_dir,\"FDS_media\", month)\n",
    "    if not os.path.exists(month_directory):\n",
    "        os.makedirs(month_directory)\n",
    "\n",
    "    csv_file = open(os.path.join(month_directory, \"data.csv\"), \"w\")\n",
    "    writer = csv.writer(csv_file, delimiter=\",\")\n",
    "    writer.writerow(['file', 'sender', 'sent'])\n",
    "\n",
    "    for msg in messages:\n",
    "        phts = msg[\"photos\"]\n",
    "        \n",
    "        date = str(datetime.fromtimestamp(float(msg['timestamp_ms'])/ 1000.0).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        for pht in phts:\n",
    "            uri = str(pht['uri'])\n",
    "            if uri.startswith(\"http://\") or uri.startswith(\"https://\"):\n",
    "                continue\n",
    "\n",
    "            file_name = os.path.split(pht['uri'])[1]\n",
    "           \n",
    "\n",
    "            print(pht)\n",
    "            photo_url = os.path.join(conversation_dir, \"photos\", file_name)\n",
    "            try:\n",
    "                shutil.copy2(photo_url, os.path.join(month_directory, file_name))\n",
    "            except FileNotFoundError:\n",
    "                file_name = \"[NOT FOUND] \" + file_name\n",
    "\n",
    "            writer.writerow((file_name, msg['sender_name'], date))\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "    directory_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import csv\n",
    "\n",
    "media = []\n",
    "\n",
    "for msg in msg_json['messages']:\n",
    "    if \"photos\" in msg:\n",
    "        media.append(msg)\n",
    "    elif \"videos\" in msg:\n",
    "        media.append(msg)\n",
    "\n",
    "ordered_media = sorted(media, key= lambda med : med['timestamp_ms'])\n",
    "\n",
    "media_per_month_dict = defaultdict(list)\n",
    "\n",
    "for medium in media:\n",
    "    date = str(datetime.fromtimestamp(float(medium['timestamp_ms'])/ 1000.0).strftime('%Y-%B'))\n",
    "    \n",
    "    media_per_month_dict[date].append(medium)\n",
    "\n",
    "conversation_dir = os.path.split(result_name)[0]\n",
    "\n",
    "for month, messages in media_per_month_dict.items():\n",
    "    month_directory = os.path.join(conversation_dir,\"FDS_media\", month)\n",
    "    if not os.path.exists(month_directory):\n",
    "        os.makedirs(month_directory)\n",
    "\n",
    "    csv_file = open(os.path.join(month_directory, \"data.csv\"), \"w\")\n",
    "    writer = csv.writer(csv_file, delimiter=\",\")\n",
    "    writer.writerow(['file', 'sender', 'sent'])\n",
    "\n",
    "    for msg in messages:\n",
    "        meds = None\n",
    "\n",
    "        if 'photos' in msg:\n",
    "            meds = msg[\"photos\"]\n",
    "        elif 'videos' in msg:\n",
    "            meds = msg['videos']\n",
    "        \n",
    "        date = str(datetime.fromtimestamp(float(msg['timestamp_ms'])/ 1000.0).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        for med in meds:\n",
    "            uri = str(med['uri'])\n",
    "            if uri.startswith(\"http://\") or uri.startswith(\"https://\"):\n",
    "                continue\n",
    "\n",
    "            file_name = os.path.split(med['uri'])[1]\n",
    "           \n",
    "            print(med)\n",
    "            photo_url = os.path.join(conversation_dir, \"photos\" if 'photos' in msg else \"videos\", file_name)\n",
    "            try:\n",
    "                shutil.copy2(photo_url, os.path.join(month_directory, file_name))\n",
    "            except FileNotFoundError:\n",
    "                file_name = \"[NOT FOUND] \" + file_name\n",
    "\n",
    "            writer.writerow((file_name, msg['sender_name'], date))\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "    directory_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
